{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2636ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "answer = pd.read_csv(r'golden_standard/pubmedqa/test.csv')\n",
    "total_numbers = len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f62ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '1001'\n",
    "fpub = pd.read_csv(f'{date}/result_from_server/result_pubmedqa.csv')\n",
    "ORG = pd.read_csv(f'{date}/result_from_server/result_ORG_BENCHMARK.csv')\n",
    "fdpub = pd.read_csv(f'{date}/result_from_server/result_dreaddit.csv')\n",
    "f1dpub = pd.read_csv(f'{date}/result_from_server/result_dreaddit-1percentpubmedqa.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6e9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_ABC = {\n",
    "    \"A\": \"Yes\", \"B\": \"No\", \"C\": \"Maybe\",\n",
    "    \"a\": \"Yes\", \"b\": \"No\", \"c\": \"Maybe\",\n",
    "    \"yes\": \"Yes\", \"no\": \"No\", \"maybe\": \"Maybe\",\n",
    "    \"Yes\": \"Yes\", \"No\": \"No\", \"Maybe\": \"Maybe\"\n",
    "}\n",
    "\n",
    "def normalize_label(x: str) -> str:\n",
    "    x = str(x).strip()\n",
    "    return MAP_ABC.get(x, x)\n",
    "\n",
    "ORG['prediction'] = ORG['prediction'].apply(normalize_label)\n",
    "fpub['prediction'] = fpub['prediction'].apply(normalize_label)\n",
    "fdpub['prediction'] = fdpub['prediction'].apply(normalize_label)\n",
    "f1dpub['prediction'] = f1dpub['prediction'].apply(normalize_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2187f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_decision\n",
      "yes      66\n",
      "no       31\n",
      "maybe     8\n",
      "Name: count, dtype: int64\n",
      "prediction\n",
      "Yes    83\n",
      "No     22\n",
      "Name: count, dtype: int64\n",
      "prediction\n",
      "Yes    96\n",
      "No      9\n",
      "Name: count, dtype: int64\n",
      "prediction\n",
      "No    105\n",
      "Name: count, dtype: int64\n",
      "prediction\n",
      "Yes      81\n",
      "No       22\n",
      "Maybe     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(answer['final_decision'].value_counts())\n",
    "print(ORG['prediction'].value_counts())\n",
    "print(fpub['prediction'].value_counts())\n",
    "print(fdpub['prediction'].value_counts())\n",
    "print(f1dpub['prediction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ae1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same(test, answer):\n",
    "    return list(test['prediction'].str.lower() == answer['final_decision'].str.lower()).count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c39bd311",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpub_accuracy = check_same(fpub,answer)/total_numbers\n",
    "ORG_accuracy = check_same(ORG,answer)/total_numbers\n",
    "fdpub_accuracy = check_same(fdpub,answer)/total_numbers\n",
    "f1dpub_accuracy = check_same(f1dpub,answer)/total_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26060e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy without the finetuning is 0.6476190476190476\n",
      "accuracy after finetune by the pubmedqa is 0.6095238095238096\n",
      "accuracy after finetune by the pubmedqa than dreaddit is 0.29523809523809524\n",
      "accuracy after finetune by the pubmedqa than dreaddit (1% data in pubmedqa) is 0.5904761904761905\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy without the finetuning is {ORG_accuracy}')\n",
    "print(f'accuracy after finetune by the pubmedqa is {fpub_accuracy}')\n",
    "print(f'accuracy after finetune by the pubmedqa than dreaddit is {fdpub_accuracy}')\n",
    "print(f'accuracy after finetune by the pubmedqa than dreaddit (1% data in pubmedqa) is {f1dpub_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd13bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative gain [pubmedqa + dreaddit] / [pubmedqa]: 0.48437499999999994\n",
      "relative fain [pubmedqa + dreaddit with 1% pubmedqa] / [pubmedqa]: 0.9687499999999999\n"
     ]
    }
   ],
   "source": [
    "print(f'relative gain [pubmedqa + dreaddit] / [pubmedqa]: {fdpub_accuracy / fpub_accuracy}')\n",
    "print(f'relative fain [pubmedqa + dreaddit with 1% pubmedqa] / [pubmedqa]: {f1dpub_accuracy / fpub_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae18bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

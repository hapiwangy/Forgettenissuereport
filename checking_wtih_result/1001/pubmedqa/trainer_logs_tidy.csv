entropy,epoch,grad_norm,learning_rate,loss,mean_token_accuracy,num_tokens,step
1.8436169415712356,0.4878048780487805,5.46875,0.0001922611651933683,2.0703,0.6163657173514366,44961.0,20
1.9804494708776474,0.975609756097561,4.125,0.00016026346363792567,2.0455,0.6369925796985626,89119.0,40
0.9944723710417748,1.4634146341463414,4.78125,0.00011185204751717029,0.9986,0.7697255134582519,132680.0,60
0.8812519311904907,1.951219512195122,3.5,6.021253740350793e-05,0.8595,0.7923315033316612,177406.0,80
0.42226624935865403,2.4390243902439024,2.5,1.9409776705056516e-05,0.3244,0.918815191090107,221487.0,100
0.30342225804924966,2.926829268292683,2.203125,5.570474529481562e-07,0.2378,0.9390499889850616,265323.0,120
